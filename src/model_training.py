import os
import time
import json
from pathlib import Path

print("AUTOGLUON: –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –î–õ–Ø –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –ó–ê–ú–ö–û–í")

PROJECT_ROOT = Path(__file__).parent.parent

# –ü—É—Ç–∏
DATA_DIR = PROJECT_ROOT / "data" / "processed"
MODELS_DIR = PROJECT_ROOT / "models"
REPORTS_DIR = PROJECT_ROOT / "reports"

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
MODELS_DIR.mkdir(exist_ok=True)
REPORTS_DIR.mkdir(exist_ok=True)

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
MODEL_NAME = "autogluon_castle_classifier"
TIME_LIMIT = 600  # 10 –º–∏–Ω—É—Ç –Ω–∞ –ø–æ–∏—Å–∫ –º–æ–¥–µ–ª–∏ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö)
IMAGE_SIZE = (224, 224)  # –î–æ–ª–∂–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å —Ä–∞–∑–º–µ—Ä–æ–º –∏–∑ data_preparation.py

print(f"–î–∞–Ω–Ω—ã–µ: {DATA_DIR}")
print(f"–ú–æ–¥–µ–ª–∏ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {MODELS_DIR}")
print(f"‚è±–õ–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ: {TIME_LIMIT} —Å–µ–∫ ({TIME_LIMIT/60:.1f} –º–∏–Ω)")

def check_data():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ."""

    print("\n–ü–†–û–í–ï–†–Ø–Æ –î–ê–ù–ù–´–ï...")

    required_folders = ["train", "val"]
    class_folders = ["class_0_romanesque", "class_1_gothic", "class_2_renaissance"]

    issues = []

    for split in required_folders:
        split_path = DATA_DIR / split
        if not split_path.exists():
            issues.append(f"–ü–∞–ø–∫–∞ {split} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {split_path}")
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª–∞—Å—Å—ã –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π split-–ø–∞–ø–∫–∏
        for class_folder in class_folders:
            class_path = split_path / class_folder
            if not class_path.exists():
                issues.append(f"–ü–∞–ø–∫–∞ –∫–ª–∞—Å—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {class_path}")
            else:
                # –°—á–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                images = list(class_path.glob("*.jpg")) + list(class_path.glob("*.png")) + list(class_path.glob("*.jpeg"))
                if len(images) == 0:
                    issues.append(f"–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤: {class_path}")
                else:
                    print(f" {split}/{class_folder}: {len(images)} —Ñ–æ—Ç–æ")

    if issues:
        print("\n–ü–†–û–ë–õ–ï–ú–´ –° –î–ê–ù–ù–´–ú–ò:")
        for issue in issues:
            print(f"   - {issue}")
        return False

    print("–í—Å–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –º–µ—Å—Ç–µ!")
    return True


def train_with_autogluon():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è —Å AutoGluon."""

    print("\n–ó–ê–ü–£–°–ö–ê–Æ AUTOGLUON...")

    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º AutoGluon (–¥–µ–ª–∞–µ–º —ç—Ç–æ –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –æ—à–∏–±–∫–∏ –∏–º–ø–æ—Ä—Ç–∞)
    try:
        from autogluon.multimodal import MultiModalPredictor
        import pandas as pd
    except ImportError as e:
        print(f"\n–û–®–ò–ë–ö–ê –ò–ú–ü–û–†–¢–ê: {e}")
        print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ AutoGluon: pip install autogluon")
        return None

    # 1. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –í –§–û–†–ú–ê–¢–ï –î–õ–Ø AUTOGLUON
    print("\n–ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•...")

    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã —Å –ø—É—Ç—è–º–∏ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
    def prepare_dataframe(split_name):
        data = []
        split_path = DATA_DIR / split_name

        for class_folder in ["class_0_romanesque", "class_1_gothic", "class_2_renaissance"]:
            class_path = split_path / class_folder
            if not class_path.exists():
                continue

            # –ü—Ä–æ—Å—Ç–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –ø–∞–ø–∫–∏ –≤ —á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
            class_name_map = {
                "class_0_romanesque": "–†–æ–º–∞–Ω—Å–∫–∏–π",
                "class_1_gothic": "–ì–æ—Ç–∏—á–µ—Å–∫–∏–π",
                "class_2_renaissance": "–†–µ–Ω–µ—Å—Å–∞–Ω—Å"
            }
            label = class_name_map.get(class_folder, class_folder)

            # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            for ext in ["*.jpg", "*.jpeg", "*.png"]:
                for img_path in class_path.glob(ext):
                    data.append({
                        "image": str(img_path),
                        "label": label
                    })

        return pd.DataFrame(data)

    # –°–æ–∑–¥–∞—ë–º DataFrames
    train_df = prepare_dataframe("train")
    val_df = prepare_dataframe("val")

    print(f" –û–±—É—á–∞—é—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(train_df)}")
    print(f" –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(val_df)}")

    if len(train_df) == 0:
        print("–ù–µ—Ç –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö!")
        return None

    # 2. –ù–ê–°–¢–†–û–ô–ö–ê –ò –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò
    print("\n–ù–ê–°–¢–†–ê–ò–í–ê–Æ –ò –û–ë–£–ß–ê–Æ –ú–û–î–ï–õ–¨...")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
    label_column = "label"

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å
    predictor = MultiModalPredictor(
        label=label_column,
        path=str(MODELS_DIR / MODEL_NAME),  # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        problem_type="multiclass",  # –ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        eval_metric="accuracy",     # –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        verbosity=2,                # –£—Ä–æ–≤–µ–Ω—å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –ª–æ–≥–æ–≤
    )

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    start_time = time.time()

    predictor.fit(
        train_data=train_df,
        tuning_data=val_df,  # –î–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
        time_limit=TIME_LIMIT,  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        presets="medium_quality",  # –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —Å–∫–æ—Ä–æ—Å—Ç—å—é –∏ –∫–∞—á–µ—Å—Ç–≤–æ–º
    )

    training_time = time.time() - start_time
    print(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–Ω—è–ª–æ: {training_time:.1f} —Å–µ–∫")

    # 3. –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò
    print("\n–û–¶–ï–ù–ò–í–ê–Æ –ö–ê–ß–ï–°–¢–í–û –ú–û–î–ï–õ–ò...")

    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ - –æ—Ü–µ–Ω–∏–≤–∞–µ–º –Ω–∞ –Ω–∏—Ö
    test_df = prepare_dataframe("test") if (DATA_DIR / "test").exists() else None

    if test_df is not None and len(test_df) > 0:
        print(f"–¢–µ—Å—Ç–∏—Ä—É—é –Ω–∞ {len(test_df)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö...")

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        predictions = predictor.predict(test_df)

        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å
        from sklearn.metrics import accuracy_score
        accuracy = accuracy_score(test_df[label_column], predictions)
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {accuracy:.2%}")

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        evaluation = predictor.evaluate(test_df, metrics=["accuracy", "f1_macro"])
        print(f"–î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: {evaluation}")
    else:
        print("–¢–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –æ—Ü–µ–Ω–∫–∞ —Ç–æ–ª—å–∫–æ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
        accuracy = 0.0

    # 4. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
    print("\n–°–û–•–†–ê–ù–Ø–Æ –†–ï–ó–£–õ–¨–¢–ê–¢–´...")

    # –ú–æ–¥–µ–ª—å —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤ path
    print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {MODELS_DIR / MODEL_NAME}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
    model_info = {
        "model_name": MODEL_NAME,
        "training_time_seconds": training_time,
        "time_limit": TIME_LIMIT,
        "image_size": IMAGE_SIZE,
        "train_samples": len(train_df),
        "val_samples": len(val_df),
        "test_samples": len(test_df) if test_df is not None else 0,
        "test_accuracy": accuracy if 'accuracy' in locals() else None,
        "classes": ["–†–æ–º–∞–Ω—Å–∫–∏–π", "–ì–æ—Ç–∏—á–µ—Å–∫–∏–π", "–†–µ–Ω–µ—Å—Å–∞–Ω—Å"],
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
    }

    info_path = REPORTS_DIR / f"{MODEL_NAME}_info.json"
    with open(info_path, "w", encoding="utf-8") as f:
        json.dump(model_info, f, indent=2, ensure_ascii=False)

    print(f"  üìÑ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏: {info_path}")

    # 5. –¢–ï–°–¢–ò–†–£–ï–ú –ú–û–î–ï–õ–¨ –ù–ê –ü–†–ò–ú–ï–†–ê–•
    print("\n–¢–ï–°–¢–ò–†–£–Æ –ù–ê –ü–†–ò–ú–ï–†–ê–•...")

    # –ë–µ—Ä—ë–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
    if len(val_df) > 0:
        sample_df = val_df.head(3)  # –ü–µ—Ä–≤—ã–µ 3 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        sample_predictions = predictor.predict(sample_df)
        sample_proba = predictor.predict_proba(sample_df)

        print("  –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
        for i, (_, row) in enumerate(sample_df.iterrows()):
            true_label = row[label_column]
            pred_label = sample_predictions[i]
            confidence = max(sample_proba.iloc[i]) * 100

            result = "ok" if true_label == pred_label else "not ok"
            print(f"    {result} –§–æ—Ç–æ {i+1}: –ò—Å—Ç–∏–Ω–∞={true_label}, –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ={pred_label}, –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={confidence:.1f}%")

    return predictor, model_info

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è."""

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ
    if not check_data():
        print("\n–ò—Å–ø—Ä–∞–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–æ–≤–∞.")
        return

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    result = train_with_autogluon()

    if result is None:
        print("\n–û–±—É—á–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å.")
        return

    predictor, model_info = result

    # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
    print("–û–ë–£–ß–ï–ù–ò–ï –° AUTOGLUON –ó–ê–í–ï–†–®–ï–ù–û!")

    print(f"\n–†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    if model_info["test_accuracy"] is not None:
        print(f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {model_info['test_accuracy']:.2%}")
    print(f"   –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {model_info['training_time_seconds']:.1f} —Å–µ–∫")
    print(f"   –û–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {model_info['train_samples']}")
    print(f"   –ö–ª–∞—Å—Å–æ–≤: {len(model_info['classes'])}")

    # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    if model_info["test_accuracy"] is not None:
        accuracy = model_info["test_accuracy"]
        if accuracy >= 0.85:
            print("–û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é.")
        elif accuracy >= 0.75:
            print("–•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –±–æ—Ç–µ.")
        elif accuracy >= 0.65:
            print("–ü—Ä–∏–µ–º–ª–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö.")
        else:
            print("–†–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∏–∑–∫–∏–π. –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.")

    print(f"\n–°–û–ó–î–ê–ù–ù–´–ï –§–ê–ô–õ–´:")
    print(f"   –ú–æ–¥–µ–ª—å: {MODELS_DIR / MODEL_NAME}/")
    print(f"   –û—Ç—á—ë—Ç: {REPORTS_DIR / f'{MODEL_NAME}_info.json'}")

if __name__ == "__main__":
    main()
